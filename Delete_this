import numpy as np
import os
import pickle
import tensorflow as tf
from tensorflow.keras.utils import pad_sequences, to_categorical
from feature_extractor import FeatureExtractor
from preprocess import load_captions, build_tokenizer
from model import build_model
DATASET_IMAGES = "../data/Flicker8k_Dataset/"
CAPTIONS_PATH = "../data/Flickr8k.token.txt"


# ------------------------------------------- 
# Compute the max caption length
# -------------------------------------------
def max_caption_length(captions):
    return max(len(c.split()) for img in captions for c in captions[img])


# -------------------------------------------
# Data Generator
# -------------------------------------------
def data_generator(captions, features, tokenizer, max_length, vocab_size):
    while True:
        for img_name, caption_list in captions.items():

            # Normalize filename (fix weird names like "xxx.jpg.1")
            clean_name = img_name.split('.')[0] + ".jpg"

            # Fetch feature
            feature = features.get(clean_name)
            if feature is None:
                print(f"Missing feature: {clean_name}, skipping...")
                continue

            # ----------------------------------------
            # FIX 1 — Ensure feature shape = (2048,)
            # ----------------------------------------
            feature = np.array(feature).reshape(-1)

            for cap in caption_list:

                # Convert caption → integer sequence
                seq = tokenizer.texts_to_sequences([cap])[0]

                # ----------------------------------------
                # FIX 2 — Remove words >= vocab_size
                # ----------------------------------------
                seq = [w for w in seq if w < vocab_size]

                for i in range(1, len(seq)):
                    in_seq = seq[:i]                  # partial caption
                    out_seq = seq[i]                 # next word to predict

                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]
                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]

                    # Yield the correct shapes
                    yield ((feature, in_seq), out_seq)


# -------------------------------------------
# Main Training Function
# -------------------------------------------
def main():

    print("Loading captions...")
    captions = load_captions(CAPTIONS_PATH)

    print("Building tokenizer...")
    tokenizer = build_tokenizer(captions)
    vocab_size = len(tokenizer.word_index) + 1
    max_length = max_caption_length(captions)

    # Save tokenizer
    os.makedirs("../saved_models", exist_ok=True)
    pickle.dump(tokenizer, open("../saved_models/tokenizer.pkl", "wb"))

    print("Extracting image features...")
    fe = FeatureExtractor()
    features = {}

    for img in os.listdir(DATASET_IMAGES):
        img_path = os.path.join(DATASET_IMAGES, img)
        feature = fe.extract(img_path)

        # FIX: flatten and save clean feature
        features[img] = feature.flatten()

    print("Feature extraction completed.")

    print("Building model...")
    model = build_model(vocab_size, max_length)
    model.summary()

    print("Starting training...")

    # Build dataset
    train_dataset = tf.data.Dataset.from_generator(
        lambda: data_generator(captions, features, tokenizer, max_length, vocab_size),
        output_signature=(
            (
                tf.TensorSpec(shape=(2048,), dtype=tf.float32),
                tf.TensorSpec(shape=(max_length,), dtype=tf.int32)
            ),
            tf.TensorSpec(shape=(vocab_size,), dtype=tf.float32),
        )
    ).batch(64).prefetch(tf.data.AUTOTUNE)

    # Steps per epoch can be tuned
    model.fit(train_dataset, steps_per_epoch=1000, epochs=20, verbose=1)

    model.save("../saved_models/image_caption_model.h5")
    print("Training complete. Model saved!")


if __name__ == "__main__":
    main()
